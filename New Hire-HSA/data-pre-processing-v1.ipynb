{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Hire - Contribute to HSA\n",
    "\n",
    "Ensure new hires who enroll in  HDHP will also open and contribute to HSA within 30 days.\n",
    "\n",
    "Predict  which new hires are likely to enroll in HDHP but are not likely to open and contribute to the HSA within 30 days.\n",
    "\n",
    "For this analysis and modeling we are solely using *person_hm_choice_enrolled_integrated* (PHCE) table and we have tweaked the \"not likely to open and contribute to the HSA within 30 days from *hire date*\" to  \"not likely to open and contribute to the HSA within 30 days from *first date when they did new hire enrollment in hdhp medical plan*\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "In this notebook, we will perform below steps\n",
    "- Load raw data which is available in S3\n",
    "- Define number of days to look forward to build target variable. For eg. it is 30 days for given probelm statement\n",
    "- Pre-process the above data, this will include below items\n",
    "    - Bring down data to one row per participant (platform_person-intern_id)\n",
    "    - Build target variable `label` using 30 days logic (X days logic)\n",
    "- Handle few data exceptions  \n",
    "- Store pre-processed data in S3, which will further be tranformed using another script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "We need to edit below three cells before running the whole script.\n",
    "    \n",
    "If not editted, data will be pulled and stored from S3 bucket as per given values.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Loading Raw Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mention the bucket name where raw data is present\n",
    "bucket='adl-core-sagemaker-studio'\n",
    "\n",
    "# This is used to seperate different versions of data for whole lifecycle i.e., data pre-process, transformations, modeling and inferences.\n",
    "# Mention the version whre data is stored in given S3 bucket\n",
    "version = 'version-1'\n",
    "\n",
    "# Mention the correct directory where raw-data is present, if data is in multiple files make sure all files are present in this directory\n",
    "raw_data_path = f'external/artichauhan/HSA/train-data'\n",
    "\n",
    "# Mention all file names as string in the below list\n",
    "raw_data_fnames = ['Hype_ML_demographics_2022_06_06_HSA_4x_AM.csv','Hype_ML_demographics_2022_06_06_HSA_3x_AM.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Storing Pre-processed Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mention the bucket name where pre-processed data will be stored. Usually there will no change in bucket name\n",
    "bucket='adl-core-sagemaker-studio'\n",
    "\n",
    "# This is used to seperate different versions of data for whole lifecycle i.e., data pre-process, transformations, modeling and inferences.\n",
    "#Make sure \"version\" name is as per version of data pre-processing script. Eg. data-pre-processing-v1.ipynb means \"version-1\"\n",
    "version = 'version-1'\n",
    "\n",
    "# Mention the directory where pre-processed data will be stored. Default file name will be \"data.csv\", we can change it data export step.\n",
    "pre_processed_data_path = f'external/artichauhan/HSA/train-data/{version}/preprocessed-data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For X days logic for creating target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-> number of days to look forward and check of participant is contributing in HSA or not.\n",
    "# At time this use-case was worked upon, it was 30 days, so 'n' is taken as 30\n",
    "# This value is use at code line 26\n",
    "n = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://artifactory.alight.com/artifactory/api/pypi/python-pypi-remote/simple\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pandas --index-url https://artifactory.alight.com/artifactory/api/pypi/python-pypi-remote/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing librarires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import boto3\n",
    "import io\n",
    "import time\n",
    "import gc\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns',None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_s3(bucket,version,raw_data_path,raw_data_fnames):\n",
    "    s3 = boto3.client('s3')\n",
    "    dataset_nrows = []\n",
    "    for i, fname in enumerate(raw_data_fnames):\n",
    "        if i==0:\n",
    "            print(f'Reading file: {fname}')\n",
    "            key = f'{raw_data_path}/{fname}'\n",
    "            obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "            data = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "            dataset_nrows.append(data.shape[0])\n",
    "            print(f'\\tFile read successfully | Shape: {data.shape}')\n",
    "        else:\n",
    "            print(f'Reading file: {fname}')\n",
    "            key = f'{raw_data_path}/{fname}'\n",
    "            obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "            data2 = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "            data = data.append(data2,ignore_index=True)\n",
    "            dataset_nrows.append(data2.shape[0])\n",
    "            print(f'\\tFile read successfully | Shape: {data2.shape}')\n",
    "\n",
    "    if sum(dataset_nrows) == data.shape[0]:\n",
    "        print(f'Data from all files loaded successfully | Final Shape: {data.shape}')\n",
    "        return data.copy()\n",
    "    else:\n",
    "        print('There is discrepency in numbers')\n",
    "        print(f'\\tTotal number of rows combined in all files: {sum(dataset_nrows)}')\n",
    "        print(f'\\tAfter combining all files total number of rows are: {data.shape[0]}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: Hype_ML_demographics_2022_06_06_HSA_4x_AM.csv\n",
      "\tFile read successfully | Shape: (1160663, 35)\n",
      "Reading file: Hype_ML_demographics_2022_06_06_HSA_3x_AM.csv\n",
      "\tFile read successfully | Shape: (780960, 35)\n",
      "Data from all files loaded successfully | Final Shape: (1941623, 35)\n"
     ]
    }
   ],
   "source": [
    "data = load_data_from_s3(bucket,version,raw_data_path,raw_data_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1941623, 35)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating data type of date columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['activity_effective_begin_date'] = data['activity_effective_begin_date'].replace('2299-12-31 00:00:00','2261-12-31 00:00:00')\n",
    "data['activity_effective_begin_date'] = pd.to_datetime(data['activity_effective_begin_date'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2021-09-01\n",
       "1   2021-06-25\n",
       "2   2021-09-30\n",
       "3   2021-11-26\n",
       "4   2021-06-01\n",
       "Name: activity_effective_begin_date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['activity_effective_begin_date'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know that `ee_hsa_contribution_flag` and `er_hsa_contribution_flag` are not reliable. Therefore, we will be creating correct flag columns using respective columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['enrolled_ee_annual_hsa_contribution']\n",
    "data['ee_hsa_contribution_flag_new'] = 0\n",
    "data.loc[\n",
    "    data['enrolled_ee_annual_hsa_contribution'] > 0,\n",
    "    'ee_hsa_contribution_flag_new'\n",
    "] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['enrolled_er_annual_hsa_contribution']\n",
    "data['er_hsa_contribution_flag_new'] = 0\n",
    "data.loc[\n",
    "    data['enrolled_er_annual_hsa_contribution'] > 0,\n",
    "    'er_hsa_contribution_flag_new'\n",
    "] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Identifying new hires enrolled in any medical plan\n",
    "# df['new_hire_enrolled_medical_plan'] = 0\n",
    "# df.loc[\n",
    "#     (df['mapped_activity_rollup_level_2']=='New Hire Enrollment') &\n",
    "#     (df['is_no_coverage_option']==0) &\n",
    "#     (df['dwh_plan_brand_code'].str.contains('MDCL|MDCL-MDCR|RTEE-MDCL')),\n",
    "#     'new_hire_enrolled_medical_plan'\n",
    "# ] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying new hires enrolled in HDHP medical plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['new_hire_enrolled_hdhp_medical_plan'] = 0\n",
    "data.loc[\n",
    "    (\n",
    "        (data['source_system']=='TBA_4X') &\n",
    "        (data['mapped_activity_rollup_level_2']=='New Hire Enrollment') &\n",
    "        (data['is_no_coverage_option']==0) &\n",
    "        (data['dwh_plan_brand_code'].isin(['MDCL','MDCL-MDCR','RTEE-MDCL'])) &\n",
    "        (data['is_option_hsa_fixed']=='HSA') &\n",
    "        (data['medical_enrolled_option_type']=='HDHP')\n",
    "    ) |\n",
    "    (\n",
    "        (data['source_system']=='CBA') &\n",
    "        (data['mapped_activity_rollup_level_2']=='Other Enrollment') &\n",
    "        (data['is_no_coverage_option']==0) &\n",
    "        (data['dwh_plan_brand_code'].isin(['MDCL','MDCL-MDCR','RTEE-MDCL'])) &\n",
    "        (data['is_option_hsa_fixed']=='HSA') &\n",
    "        (data['medical_enrolled_option_type']=='HDHP')\n",
    "    ) |\n",
    "    (\n",
    "        (data['source_system']=='TBA_3X') &\n",
    "        (data['mapped_activity_rollup_level_2']=='New Hire Enrollment') &\n",
    "        (data['is_no_coverage_option']==0) &\n",
    "        (data['dwh_plan_brand_code']=='HSA')\n",
    "    ),\n",
    "    'new_hire_enrolled_hdhp_medical_plan'\n",
    "] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436719"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unique count of person who enrolled in HDHP medical plan\n",
    "data[data['new_hire_enrolled_hdhp_medical_plan']==1]['platform_person_internal_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436719"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['platform_person_internal_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Identifying new hires enrolled in HDHP medical plan and contributing to HSA - at time of New Hire Enrollment\n",
    "# data['new_hire_enrolled_hdhp_medical_plan_contributing_hsa'] = 0\n",
    "# data.loc[\n",
    "#     (\n",
    "#         (data['source_system']=='TBA_4X') &\n",
    "#         (data['mapped_activity_rollup_level_2']=='New Hire Enrollment') &\n",
    "#         (data['is_no_coverage_option']==0) &\n",
    "#         (data['dwh_plan_brand_code'].isin(['MDCL','MDCL-MDCR','RTEE-MDCL'])) &\n",
    "#         (data['is_option_hsa_fixed']=='HSA') &\n",
    "#         (data['medical_enrolled_option_type']=='HDHP') &\n",
    "#         (data['ee_hsa_contribution_flag_new']==1)\n",
    "#     ) |\n",
    "#     (\n",
    "#         (data['source_system']=='CBA') &\n",
    "#         (data['mapped_activity_rollup_level_2']=='Other Enrollment') &\n",
    "#         (data['is_no_coverage_option']==0) &\n",
    "#         (data['dwh_plan_brand_code'].isin(['MDCL','MDCL-MDCR','RTEE-MDCL'])) &\n",
    "#         (data['is_option_hsa_fixed']=='HSA') &\n",
    "#         (data['medical_enrolled_option_type']=='HDHP') &\n",
    "#         (data['ee_hsa_contribution_flag_new']==1)\n",
    "#     ) |\n",
    "#     (\n",
    "#         (data['source_system']=='TBA_3X') &\n",
    "#         (data['mapped_activity_rollup_level_2']=='New Hire Enrollment') &\n",
    "#         (data['is_no_coverage_option']==0) &\n",
    "#         (data['dwh_plan_brand_code']=='HSA') &\n",
    "#         (data['ee_hsa_contribution_flag_new']==1)\n",
    "#     ),\n",
    "#     'new_hire_enrolled_hdhp_medical_plan_contributing_hsa'\n",
    "# ] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering data for partcipants who had new hire enrollment in HDHP medical plan\n",
    "Exlcuding person's data who did not had new hire enrollment in HDHP medical plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1941623, 38)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filtering data for particpants who had new_hire_enrolled_hdhp_medical_plan=1 at some point of time in the given year\n",
    "ppid_enrolled_hdhp = data[data['new_hire_enrolled_hdhp_medical_plan']==1]['platform_person_internal_id'].unique()\n",
    "df = data[data['platform_person_internal_id'].isin(ppid_enrolled_hdhp)]\n",
    "del ppid_enrolled_hdhp\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1941623, 38)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting data by participant and activity begin date -> to mark row number for each particant\n",
    "df = df.sort_values(['platform_person_internal_id','activity_effective_begin_date'],ascending=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating this column to create another column which will duplicate minimum activity begin date corrsoponding to new hire enrollment in\n",
    "#in HSHP type of medical plan for each participant\n",
    "df['activity_begin_date_nhehmp'] = pd.NaT\n",
    "df.loc[df['new_hire_enrolled_hdhp_medical_plan']==1,'activity_begin_date_nhehmp'] = df['activity_effective_begin_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating column to capture first activity start date corrsponding to new hire enrollment in HDHP medical plan for particpants \n",
    "df['min_activity_begin_date_nhehmp'] = df.groupby('platform_person_internal_id')['activity_begin_date_nhehmp'].transform(lambda x: x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for nulls\n",
    "df['min_activity_begin_date_nhehmp'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating this column to create row number column for each particpant\n",
    "#this will flag row as 1 if activity_effective_begin_date > min_activity_begin_date_nhehmp\n",
    "# in case activity_effective_begin_date = min_activity_begin_date_nhehmp then if activity_begin_date_nhehmp not NULL then 1 else 0\n",
    "#above logic is implemented, in case we have muplitple rows with same date as min_activity_begin_date_nhehmp then to assign flag as 1\n",
    "#only to rows where new hire enrollment to HDHP medical plan was done\n",
    "df['activity_begin_date_nhehmp_ge_min'] = 0\n",
    "df.loc[(df['activity_effective_begin_date']>df['min_activity_begin_date_nhehmp']), 'activity_begin_date_nhehmp_ge_min'] = 1\n",
    "df.loc[(df['activity_effective_begin_date']==df['min_activity_begin_date_nhehmp']) & (df['activity_begin_date_nhehmp'].notnull()), 'activity_begin_date_nhehmp_ge_min'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning row number for each particpant's rows where activity_begin_date_nhehmp_ge_min=1, and we can use row number =1 to capture\n",
    "#first row for each particpant when theyhad new hire enrollemnt in HDHP medical plan\n",
    "df['ppid_rnum'] = df[df['activity_begin_date_nhehmp_ge_min']==1].groupby('platform_person_internal_id')['activity_effective_begin_date'].transform(lambda x: range(1,len(x)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for nulls, having nulls is not a problem. We only need to condier row number = 1 for each particpant\n",
    "#while brining the dataset to one row per participant \n",
    "df['ppid_rnum'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating this column to help create label column\n",
    "#this will check days difference between first new hire enrollment in HDHP medical plan activity date and respective row activity date\n",
    "#if the difference is less than or equal to specified number 'n' then it flag respective row as 1 else 0\n",
    "# 'n' is mentioned at start of the script\n",
    "df['activity_begin_date_within_30d_flag'] = 0\n",
    "df.loc[(df['activity_effective_begin_date']-df['min_activity_begin_date_nhehmp']).dt.days.isin(range(n+1)), 'activity_begin_date_within_30d_flag']=1\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for nulls, we do not expect nulls here\n",
    "df['activity_begin_date_within_30d_flag'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally we are creating label column\n",
    "#logic: if the particpant contributed in HSA within 30 days of forst new hire enrollment in HDHP mencial plan for given enrolled_plan_year\n",
    "#not necessaryly at time of enrollment then rows for the particpant will be flaged as 1 else 0\n",
    "#also there is not checks on other columns while considering ee_hsa_contribution_flag=1\n",
    "#column will have null values for rows where activity_begin_date_within_30d_flag=0, irrespecitve of particpant contributing or not in HSA\n",
    "#we can change the look forward days 30 days to any days by changing value of variable 'n' and re-running code for creating\n",
    "#'activity_begin_date_within_30d_flag' and 'label' columns\n",
    "df['label'] = df[df['activity_begin_date_within_30d_flag']==1].groupby('platform_person_internal_id')['ee_hsa_contribution_flag_new'].transform(lambda x: x.max())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping supporting columns used to create label column\n",
    "df.drop(\n",
    "    columns=['activity_begin_date_nhehmp',\n",
    "             'min_activity_begin_date_nhehmp',\n",
    "             'activity_begin_date_nhehmp_ge_min',\n",
    "             'activity_begin_date_within_30d_flag'\n",
    "            ],\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating new dataframe - one row per person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#condering only row number 1 for each particpant to bring down data at particpant leve;\n",
    "df = df[df['ppid_rnum']==1]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking unique count of participants\n",
    "df['platform_person_internal_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chekcing count of particpants contributing in HSA within 30 days of new hire enrollement in HDHP medical plan vs not\n",
    "# 1 -> contributing, 0 -> not contributing within 30 days \n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reversing 1 <-> 0, not label (target column is align with problem statement)\n",
    "# 1 -> particpants NOT CONTRINUTING TO HSA within 30 days of first new hire enrollement date in HDHP medical plan\n",
    "# 0 -> particpants CONTRINUTING TO HSA within 30 days of first new hire enrollement date in HDHP medical plan\n",
    "df['label'] = df['label'].map({0:1,1:0})\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping some more columns that were used to create desired dataset\n",
    "drop_columns = ['ppid_rnum','new_hire_enrolled_hdhp_medical_plan',\n",
    "                'er_hsa_contribution_flag','ee_hsa_contribution_flag_new','enrolled_plan_year','enrolled_person_plan_efenddt',\n",
    "                'enrolled_person_plan_efbegdt','activity_effective_begin_date','ee_hsa_contribution_flag',\n",
    "                'enrolled_ee_annual_hsa_contribution','medical_enrolled_option_type','is_option_hsa_fixed','dwh_plan_brand_code',\n",
    "                'is_no_coverage_option','mapped_activity_rollup_level_2']\n",
    "\n",
    "df.drop(\n",
    "    columns=drop_columns,\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'er_hsa_contribution_flag_new':'er_hsa_contribution_flag_new'}, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting pre-processed data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Uploading pre-processed data here -> s3://{bucket}/{pre_processed_data_path}/data.csv')\n",
    "\n",
    "df.to_csv(f's3://{bucket}/{pre_processed_data_path}/data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
